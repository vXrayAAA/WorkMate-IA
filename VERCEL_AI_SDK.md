# üöÄ Vercel AI SDK - Guia de Configura√ß√£o

O WorkMate AI agora usa o **Vercel AI SDK** para integra√ß√£o com m√∫ltiplos providers de IA!

---

## ‚ú® Vantagens do Vercel AI SDK

‚úÖ **Streaming nativo** - Respostas em tempo real
‚úÖ **Unified API** - Mesma interface para todos providers
‚úÖ **Type-safe** - TypeScript first
‚úÖ **Edge Ready** - Funciona em Edge Runtime
‚úÖ **React Hooks** - `useChat()` integrado

---

## üîå Providers Suportados

### 1. OpenAI (GPT-4, GPT-3.5)

```env
AI_PROVIDER=openai
OPENAI_MODEL=gpt-4o-mini
OPENAI_API_KEY=sk-...
```

**Modelos dispon√≠veis:**
- `gpt-4o` - Mais inteligente
- `gpt-4o-mini` - R√°pido e econ√¥mico ‚≠ê
- `gpt-3.5-turbo` - Mais barato

**Obter API Key:** https://platform.openai.com/api-keys

---

### 2. Anthropic (Claude)

```env
AI_PROVIDER=anthropic
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_API_KEY=sk-ant-...
```

**Modelos dispon√≠veis:**
- `claude-3-5-sonnet-20241022` - Melhor qualidade ‚≠ê
- `claude-3-haiku-20240307` - Mais r√°pido
- `claude-3-opus-20240229` - M√°xima capacidade

**Obter API Key:** https://console.anthropic.com/

---

### 3. Google Gemini

```env
AI_PROVIDER=google
GOOGLE_MODEL=gemini-1.5-flash
GOOGLE_API_KEY=AIza...
```

**Modelos dispon√≠veis:**
- `gemini-1.5-pro` - Melhor qualidade
- `gemini-1.5-flash` - R√°pido ‚≠ê
- `gemini-1.0-pro` - Est√°vel

**Obter API Key:** https://makersuite.google.com/app/apikey

---

### 4. Modo Mock (Padr√£o)

```env
AI_PROVIDER=mock
```

**Funcionalidades:**
- ‚úÖ Respostas inteligentes sem IA
- ‚úÖ N√£o requer API keys
- ‚úÖ Perfeito para demos
- ‚úÖ Zero custo

---

## üõ†Ô∏è Como Funciona

### Arquivo: `app/api/chat/route.ts`

```typescript
import { streamText } from 'ai';
import { openai } from '@ai-sdk/openai';

// Streaming de resposta
const result = await streamText({
  model: openai('gpt-4o-mini'),
  system: systemPrompt,
  messages: convertToCoreMessages(messages),
  temperature: 0.7,
});

// Retorna stream
return result.toTextStreamResponse();
```

### No Frontend (j√° implementado)

O chat consome a API normalmente via `fetch` e recebe as respostas em JSON.

Para streaming real, voc√™ pode usar o hook `useChat`:

```typescript
import { useChat } from 'ai/react';

const { messages, input, handleInputChange, handleSubmit } = useChat({
  api: '/api/chat',
});
```

---

## üìä Compara√ß√£o de Providers

| Provider | Custo | Velocidade | Qualidade | Limite Gr√°tis |
|----------|-------|------------|-----------|---------------|
| **OpenAI** | $$$ | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | $5 cr√©dito |
| **Anthropic** | $$$ | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | $5 cr√©dito |
| **Google** | $$ | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Generoso |
| **Mock** | FREE | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Ilimitado |

---

## üöÄ Deploy na Vercel

### Vari√°veis de Ambiente Necess√°rias:

**M√≠nimo (Mock):**
```
AI_PROVIDER=mock
```

**Com IA Real:**
```
AI_PROVIDER=openai
OPENAI_MODEL=gpt-4o-mini
OPENAI_API_KEY=sk-...
```

### Passo a Passo:

1. **Acesse:** https://vercel.com/vxrayaaas-projects/workmate-nextjs
2. **Settings ‚Üí Environment Variables**
3. **Adicione as vari√°veis**
4. **Redeploy** (Deployments ‚Üí ... ‚Üí Redeploy)

---

## üí° Dicas de Uso

### Para Desenvolvimento Local:

```bash
# .env.local
AI_PROVIDER=mock  # R√°pido, sem custo
```

### Para Produ√ß√£o:

```bash
# Vercel Environment Variables
AI_PROVIDER=openai
OPENAI_MODEL=gpt-4o-mini
OPENAI_API_KEY=sk-...
```

### Custos Estimados:

**GPT-4o-mini:**
- $0.15 / 1M input tokens
- $0.60 / 1M output tokens
- ~1000 conversas = $1

**Claude 3.5 Sonnet:**
- $3 / 1M input tokens  
- $15 / 1M output tokens
- ~200 conversas = $1

**Gemini 1.5 Flash:**
- FREE at√© 15 req/min
- Ap√≥s: $0.075 / 1M tokens
- Muito generoso!

---

## üîß Troubleshooting

### Erro: "API key not found"

```bash
# Verifique se as vari√°veis est√£o configuradas
echo $AI_PROVIDER
echo $OPENAI_API_KEY
```

### Erro: "Rate limit exceeded"

- **Google:** 15 req/min (free tier)
- **OpenAI:** 3500 req/min (tier 1)
- **Solu√ß√£o:** Adicione retry ou use outro provider

### Streaming n√£o funciona

O c√≥digo atual usa JSON response normal. Para streaming real:

```typescript
// No frontend, use:
const response = await fetch('/api/chat', {
  method: 'POST',
  body: JSON.stringify({ agent, message }),
});

const reader = response.body.getReader();
// ... processar stream
```

---

## üìö Documenta√ß√£o Oficial

- **Vercel AI SDK:** https://sdk.vercel.ai/docs
- **OpenAI:** https://platform.openai.com/docs
- **Anthropic:** https://docs.anthropic.com
- **Google AI:** https://ai.google.dev/docs

---

## ‚úÖ Checklist Pr√©-Deploy

- [ ] Escolher provider (mock, openai, anthropic, google)
- [ ] Obter API key do provider
- [ ] Configurar vari√°veis de ambiente
- [ ] Testar localmente
- [ ] Deploy na Vercel
- [ ] Adicionar vari√°veis na Vercel
- [ ] Redeploy
- [ ] Testar em produ√ß√£o

---

**üéâ Pronto! Seu WorkMate AI est√° agora com IA de verdade!**

Para demonstra√ß√µes sem custo, mantenha `AI_PROVIDER=mock` ‚ú®
